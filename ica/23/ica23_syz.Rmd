---
title: "ica22_syz"
author: "Shuangyu Zhao"
date: "2023-04-11"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r}
library(neuralnet)
library(caret)
```

1.	For the heart dataset
```{r}
heart <- read.csv("/Users/apple/Desktop/STT811_appl_stat_model/data/Heart.csv")
heart <- na.omit(heart)
```

a.	With a 70-30 train test split, experiment with building a few different neural networks (both single and multi-layer), using RestBP and MaxHR and a logistic activation function.  Which one has the best performance?
```{r}
split_pct <- 0.7
n <- length(heart$X)*split_pct # train size
row_samp <- sample(1:length(heart$X), n, replace = FALSE)
train <- heart[row_samp,]
test <- heart[-row_samp,]
head(train)
```

```{r}
nn <- neuralnet(AHD ~ RestBP + MaxHR + Age + Chol, data = train, act.fct = 'logistic', hidden = c(3), linear.output = FALSE)
pred <- ifelse(predict(nn, test)[,1] > 0.5, 'No', 'Yes')
confusionMatrix(as.factor(pred), as.factor(test$AHD))
```



b.	Build a neural network with 2 nodes in the single hidden layer.  Manually duplicate the predictions on the test dataset by directly using the weights and logistic functions of the inputs.
```{r}
xval <- cbind(test$RestBP,test$MaxHR)
logi <- function(x) 1/(1 + exp(-1*x))
n1 <- logi(nn$result.matrix[4] + nn$result.matrix[5]*xval[,1] + nn$result.matrix[6]*xval[,2])
n2 <- logi(nn$result.matrix[7] + nn$result.matrix[8]*xval[,1] + nn$result.matrix[9]*xval[,2])
pr <- logi(nn$result.matrix[10] + nn$result.matrix[11]*n1 + nn$result.matrix[12]*n2)
cbind(pr,predict(nn, test)[,1])
```

